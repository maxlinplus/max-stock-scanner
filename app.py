import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import re
import os
from datetime import datetime

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="PTT è‚¡å¸‚åæŒ‡æ¨™è§€æ¸¬ç«™",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- æª”æ¡ˆè™•ç† (è‡ªå‹•è¨˜æ†¶åŠŸèƒ½) ---
KEY_FILE = "api_key.txt"

def load_key():
    """å¾æª”æ¡ˆè®€å– Key"""
    if os.path.exists(KEY_FILE):
        try:
            with open(KEY_FILE, "r", encoding="utf-8") as f:
                return f.read().strip()
        except:
            return ""
    return ""

def save_key(key):
    """å°‡ Key å¯«å…¥æª”æ¡ˆ"""
    try:
        with open(KEY_FILE, "w", encoding="utf-8") as f:
            f.write(key)
    except:
        pass

# --- æ ¸å¿ƒå‡½æ•¸ ---
def get_soup(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.ptt.cc/bbs/Stock/index.html',
            'Connection': 'keep-alive'
        }
        cookies = {'over18': '1'}
        response = requests.get(url, cookies=cookies, headers=headers, timeout=10)
        if response.status_code != 200: return None
        return BeautifulSoup(response.text, 'html.parser')
    except: return None

def extract_timestamp(url):
    match = re.search(r'M\.(\d+)', url)
    return int(match.group(1)) if match else 0

def parse_article(url):
    soup = get_soup(url)
    if not soup: return None
    try:
        meta = soup.find_all('span', class_='article-meta-value')
        if not meta or len(meta) < 4: return None
        
        author = meta[0].text.strip()
        title = meta[2].text.strip()
        date = meta[3].text.strip()
        main_content = soup.find(id="main-content")
        
        pushes = main_content.find_all('div', class_='push')
        p_cnt = sum(1 for p in pushes if 'æ¨' in p.text)
        b_cnt = sum(1 for p in pushes if 'å™“' in p.text)
        
        for t in main_content.find_all(['div', 'span'], class_=['article-meta-tag', 'article-meta-value', 'push', 'richcontent']): 
            t.decompose()
        
        content = main_content.get_text().strip()[:5000]
        formatted_text = f"\n{'='*30}\nğŸ“„ æ¨™é¡Œ: {title}\nğŸ“… æ™‚é–“: {date}\nğŸ‘¤ ä½œè€…: {author}\nğŸ“Š äº’å‹•: æ¨ {p_cnt} | å™“ {b_cnt}\n\n{content}\n"
        return formatted_text, title, date
    except: return None

def find_valid_model(api_key):
    """åµæ¸¬å¯ç”¨æ¨¡å‹ (Pro å„ªå…ˆ)"""
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if 'models' in data:
                valid_models = [m['name'].replace('models/', '') for m in data['models'] if 'generateContent' in m.get('supportedGenerationMethods', [])]
                # å„ªå…ˆé †åº
                for m in valid_models:
                    if "gemini-1.5-pro" in m: return m
                for m in valid_models:
                    if "gemini-1.0-pro" in m: return m
                for m in valid_models:
                    if "gemini-1.5-flash" in m: return m
                if valid_models: return valid_models[0]
        return "gemini-1.5-flash" 
    except: return "gemini-1.5-flash"

def call_gemini_api(api_key, prompt):
    model_name = find_valid_model(api_key)
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    response = requests.post(url, headers=headers, json=data, timeout=60)
    if response.status_code == 200:
        return response.json()['candidates'][0]['content']['parts'][0]['text'], model_name
    else:
        raise Exception(f"API Error {response.status_code}: {response.text}")

# --- ç¶²é ä»‹é¢é‚è¼¯ ---

# å´é‚Šæ¬„ï¼šè¨­å®šå€
with st.sidebar:
    st.header("âš™ï¸ åƒæ•¸è¨­å®š")
    
    # è‡ªå‹•è¨˜æ†¶é‚è¼¯
    saved_key = load_key()
    api_key_input = st.text_input("Gemini API Key", value=saved_key, type="password", help="è¼¸å…¥å¾Œç³»çµ±æœƒè‡ªå‹•å„²å­˜")
    if api_key_input and api_key_input != saved_key:
        save_key(api_key_input)
        st.toast("ğŸ’¾ API Key å·²è‡ªå‹•å„²å­˜ï¼", icon="âœ…")
    
    st.session_state.api_key = api_key_input

    keyword_input = st.text_input("è‚¡ç¥¨ä»£è™Ÿ (ç©ºç™½éš”é–‹)", value="2330 å°ç©é›»")
    limit_count = st.number_input("ä¸‹è¼‰ç¯‡æ•¸", min_value=1, max_value=20, value=5)
    
    st.divider()
    if saved_key:
        st.caption("âœ… ç›®å‰å·²è¼‰å…¥è‡ªå‹•å„²å­˜çš„ Key")
    else:
        st.caption("ğŸ’¡ é¦–æ¬¡è¼¸å…¥å¾Œï¼Œç³»çµ±å°‡è‡ªå‹•å»ºç«‹ `api_key.txt` å¹«æ‚¨è¨˜ä½ã€‚")

# ä¸»ç•«é¢
st.title("ğŸ“ˆ PTT è‚¡å¸‚åæŒ‡æ¨™è§€æ¸¬ç«™")
st.markdown("çµåˆ **PTT çˆ¬èŸ²** èˆ‡ **Gemini Pro** æ¨¡å‹ï¼Œè‡ªå‹•åˆ¤è®€æ•£æˆ¶æƒ…ç·’ã€‚")

# åˆå§‹åŒ– session state
if "scraped_data" not in st.session_state:
    st.session_state.scraped_data = ""
if "logs" not in st.session_state:
    st.session_state.logs = []

# æŒ‰éˆ•ï¼šé–‹å§‹æœå°‹
if st.button("ğŸš€ é–‹å§‹æœå°‹ & ä¸‹è¼‰", use_container_width=True):
    st.session_state.logs = [] 
    st.session_state.scraped_data = ""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    keywords = keyword_input.split()
    links = set()
    
    # 1. æœå°‹é€£çµ
    for kw in keywords:
        status_text.text(f"æ­£åœ¨æœå°‹: {kw}...")
        soup = get_soup(f"https://www.ptt.cc/bbs/Stock/search?q={kw}")
        if soup:
            for t in soup.find_all('div', class_='title'):
                a = t.find('a')
                if a: links.add("https://www.ptt.cc" + a['href'])
    
    if not links:
        st.error("âŒ æ‰¾ä¸åˆ°ç›¸é—œæ–‡ç« ")
    else:
        # 2. æ’åºèˆ‡ä¸‹è¼‰
        sorted_links = sorted(list(links), key=extract_timestamp, reverse=True)[:limit_count]
        status_text.text(f"æ‰¾åˆ° {len(sorted_links)} ç¯‡ï¼Œé–‹å§‹ä¸‹è¼‰å…§å®¹...")
        
        full_text = ""
        for i, link in enumerate(sorted_links):
            res = parse_article(link)
            if res:
                text, title, date = res
                full_text += text
                st.session_state.logs.append(f"âœ… [{date}] {title}")
            else:
                st.session_state.logs.append(f"âŒ è®€å–å¤±æ•—: {link}")
            
            progress_bar.progress((i + 1) / len(sorted_links))
            time.sleep(0.2)
            
        st.session_state.scraped_data = full_text
        st.success("ğŸ‰ çˆ¬èŸ²åŸ·è¡Œå®Œæˆï¼")

# é¡¯ç¤ºæŠ“å–ç´€éŒ„
if st.session_state.logs:
    with st.expander("ğŸ“‹ æŸ¥çœ‹å·²æŠ“å–çš„æ–‡ç« åˆ—è¡¨", expanded=True):
        for log in st.session_state.logs:
            st.text(log)

# --- å‹•ä½œå€å¡Šï¼šä¸‹è¼‰èˆ‡åˆ†æ ---
if st.session_state.scraped_data:
    st.divider()
    st.subheader("ğŸ› ï¸ ä¸‹ä¸€æ­¥æ“ä½œ")
    
    # ä½¿ç”¨ columns è®“æŒ‰éˆ•ä¸¦æ’
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # åˆ†ææŒ‰éˆ•
        if st.button("ğŸ¤– å‘¼å« Gemini é€²è¡Œåˆ†æ", type="primary", use_container_width=True):
            if not st.session_state.api_key:
                st.warning("è«‹å…ˆåœ¨å·¦å´è¼¸å…¥ Gemini API Key")
            else:
                with st.spinner("ğŸ§  AI æ­£åœ¨é–±è®€æ–‡ç« ä¸¦åˆ†ææ•£æˆ¶å¿ƒç†..."):
                    try:
                        prompt = f"""
                        è§’è‰²è¨­å®šï¼šä½ æ˜¯ä¸€ä½ç²¾é€šå°è‚¡æ•£æˆ¶å¿ƒç†å­¸èˆ‡è¡Œç‚ºé‡‘èå­¸çš„è³‡æ·±äº¤æ˜“å“¡ã€‚
                        ä»»å‹™ï¼šåˆ†æä»¥ä¸‹ PTT è‚¡æ¿è¨è«–å…§å®¹ã€‚
                        
                        è«‹è¼¸å‡ºç°¡æ½”å ±å‘Šï¼š
                        1. ã€æƒ…ç·’æº«åº¦è¨ˆã€‘ (0-100åˆ†)ï¼š0=æ¥µåº¦ææ…Œ(è²·é»)ï¼Œ100=æ¥µåº¦ç‹‚ç†±(è³£é»)ã€‚
                        2. ã€æ•£æˆ¶å…±è­˜ã€‘ï¼šå¤§å®¶ç¾åœ¨ä¸»è¦åœ¨çœ‹å¤šé‚„æ˜¯çœ‹ç©ºï¼Ÿç†ç”±æ˜¯ä»€éº¼ï¼Ÿ
                        3. ã€åæŒ‡æ¨™æ“ä½œå»ºè­°ã€‘ï¼šåŸºæ–¼ã€Œäººå¤šçš„åœ°æ–¹ä¸è¦å»ã€åŸå‰‡ï¼Œç¾åœ¨é©åˆé€²å ´ã€å‡ºå ´é‚„æ˜¯è§€æœ›ï¼Ÿ
                        4. ã€é—œéµè­‰æ“šã€‘ï¼šå¼•ç”¨ 1-2 å‰‡æœ€å…·ä»£è¡¨æ€§çš„æ¨æ–‡æˆ–å…§æ–‡ã€‚

                        è³‡æ–™å…§å®¹ï¼š
                        {st.session_state.scraped_data[:40000]}
                        """
                        
                        result, model_used = call_gemini_api(st.session_state.api_key, prompt)
                        
                        st.divider()
                        st.subheader(f"ğŸ“Š åˆ†æå ±å‘Š (ä½¿ç”¨æ¨¡å‹: {model_used})")
                        st.markdown(result)
                        
                    except Exception as e:
                        st.error(f"åˆ†æå¤±æ•—: {str(e)}")

    with col2:
        # ä¸‹è¼‰æŒ‰éˆ•
        # è‡ªå‹•ç”¢ç”Ÿæª”å: ptt_stock_YYYYMMDD_HHMMSS.txt
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_kw = re.sub(r'[\\/*?:"<>|]', "_", keyword_input.replace(" ", "_"))
        filename = f"ptt_{safe_kw}_{timestamp}.txt"
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰æ–‡å­—æª” (.txt)",
            data=st.session_state.scraped_data,
            file_name=filename,
            mime="text/plain",
            use_container_width=True
        )

# é å°¾
st.divider()
st.caption("Powered by Streamlit & Google Gemini API")