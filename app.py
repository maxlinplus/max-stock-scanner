import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import re
import os
from datetime import datetime, timedelta, timezone

# --- è²¡ç¶“å¥—ä»¶ ---
import yfinance as yf
import pandas as pd

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="PTT è‚¡å¸‚æˆ°æƒ…å®¤",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

TW_TZ = timezone(timedelta(hours=8))

def get_tw_time_str():
    return datetime.now(TW_TZ).strftime("%Y-%m-%d_%H-%M-%S")

# --- æª”æ¡ˆè™•ç† ---
KEY_FILE = "api_key.txt"

def load_key():
    if os.path.exists(KEY_FILE):
        try:
            with open(KEY_FILE, "r", encoding="utf-8") as f:
                return f.read().strip()
        except: return ""
    return ""

def save_key(key):
    try:
        with open(KEY_FILE, "w", encoding="utf-8") as f:
            f.write(key)
    except: pass

# ==========================================
# 1. æŠ€è¡“é¢æ¨¡çµ„ (yfinance)
# ==========================================
def calculate_technical_indicators(ticker_symbol):
    try:
        stock_id = f"{ticker_symbol}.TW" if not ticker_symbol.endswith(".TW") else ticker_symbol
        stock = yf.Ticker(stock_id)
        df = stock.history(period="3mo")
        
        if df.empty or len(df) < 20:
            return "âŒ ç„¡æ³•ç²å–è‚¡åƒ¹è³‡æ–™ (å¯èƒ½æ˜¯ä»£è™ŸéŒ¯èª¤)"

        # --- è¨ˆç®—æŒ‡æ¨™ ---
        df['MA5'] = df['Close'].rolling(window=5).mean()
        df['MA20'] = df['Close'].rolling(window=20).mean()
        df['MA60'] = df['Close'].rolling(window=60).mean()
        
        # RSI (14)
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # KD (9)
        low_min = df['Low'].rolling(window=9).min()
        high_max = df['High'].rolling(window=9).max()
        df['RSV'] = (df['Close'] - low_min) / (high_max - low_min) * 100
        df['K'] = df['RSV'].ewm(com=2).mean()
        df['D'] = df['K'].ewm(com=2).mean()

        t = df.iloc[-1]
        # åŠ å…¥ç•¶ä¸‹æŠ“å–æ™‚é–“
        fetch_time = datetime.now(TW_TZ).strftime('%Y-%m-%d %H:%M')
        
        y_info = ""
        kd_sig = ""
        
        if len(df) > 1:
            y = df.iloc[-2]
            change = t['Close'] - y['Close']
            pct = (change / y['Close']) * 100
            
            vol_change = t['Volume'] - y['Volume']
            vol_str = f"å¢åŠ  {int(vol_change/1000)}" if vol_change > 0 else f"æ¸›å°‘ {int(abs(vol_change)/1000)}"
            
            y_info = f"""
            - æ¼²è·Œ: {change:.2f} ({pct:.2f}%)
            - é‡èƒ½: è¼ƒæ˜¨æ—¥{vol_str}å¼µ
            """
            
            if y['K'] < y['D'] and t['K'] > t['D']: kd_sig = "ğŸ”¥ é»ƒé‡‘äº¤å‰ (è½‰å¼·è¨Šè™Ÿ)"
            elif y['K'] > y['D'] and t['K'] < t['D']: kd_sig = "âš ï¸ æ­»äº¡äº¤å‰ (è½‰å¼±è¨Šè™Ÿ)"
        else:
            y_info = "(ç„¡æ˜¨æ—¥è³‡æ–™)"

        report = f"""
        ã€å®˜æ–¹æŠ€è¡“æ•¸æ“š (æŠ“å–æ™‚é–“: {fetch_time})ã€‘
        1. åƒ¹æ ¼èˆ‡é‡èƒ½ï¼š
           - æ”¶ç›¤åƒ¹: {t['Close']:.2f}
           {y_info}
           - ä»Šæ—¥æˆäº¤é‡: {int(t['Volume']/1000)} å¼µ

        2. å‡ç·šç‹€æ…‹ï¼š
           - MA5 (é€±ç·š): {t['MA5']:.2f} ({'ç«™ä¸Š' if t['Close'] > t['MA5'] else 'è·Œç ´'})
           - MA20 (æœˆç·š): {t['MA20']:.2f}
           - MA60 (å­£ç·š): {t['MA60']:.2f}

        3. æŠ€è¡“æŒ‡æ¨™ï¼š
           - RSI (14): {t['RSI']:.2f} ({'éç†±' if t['RSI']>70 else 'è¶…è³£' if t['RSI']<30 else 'ä¸­æ€§'})
           - KD (9): K={t['K']:.2f}, D={t['D']:.2f}
           - è¨Šè™Ÿ: {kd_sig if kd_sig else 'ç„¡ç‰¹æ®Šäº¤å‰'}
        """
        return report

    except Exception as e:
        return f"âŒ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—éŒ¯èª¤: {str(e)}"

# ==========================================
# 2. PTT çˆ¬èŸ²æ¨¡çµ„ (æ¨æ–‡å®Œæ•´ç‰ˆ)
# ==========================================
def get_ptt_soup(url):
    headers = {'User-Agent': 'Mozilla/5.0', 'Referer': 'https://www.ptt.cc/'}
    cookies = {'over18': '1'}
    try:
        response = requests.get(url, headers=headers, cookies=cookies, timeout=10)
        if response.status_code == 200:
            return BeautifulSoup(response.text, 'html.parser')
    except: pass
    return None

def extract_ptt_timestamp(url):
    match = re.search(r'M\.(\d+)', url)
    return int(match.group(1)) if match else 0

def parse_ptt_article(url):
    soup = get_ptt_soup(url)
    if not soup: return None
    try:
        meta = soup.find_all('span', class_='article-meta-value')
        if not meta or len(meta) < 4: return None
        
        author = meta[0].text.strip()
        title = meta[2].text.strip()
        date = meta[3].text.strip()
        main = soup.find(id="main-content")
        
        pushes = main.find_all('div', class_='push')
        p_cnt = sum(1 for p in pushes if 'æ¨' in p.text)
        b_cnt = sum(1 for p in pushes if 'å™“' in p.text)
        
        comments_list = []
        for p in pushes:
            try:
                tag = p.find('span', class_='push-tag').text.strip()
                user = p.find('span', class_='push-userid').text.strip()
                content = p.find('span', class_='push-content').text.strip().replace(': ', '')
                ip_time_span = p.find('span', class_='push-ipdatetime')
                raw_time = ip_time_span.text.strip() if ip_time_span else ""
                clean_time = " ".join(raw_time.split()) 
                if not clean_time: clean_time = "No_Time"
                
                comments_list.append(f"[{clean_time}] {tag} {user} : {content}")
            except: continue

        for t in main.find_all(['div', 'span'], class_=['article-meta-tag', 'article-meta-value', 'push', 'richcontent']): 
            t.decompose()
        
        content = main.get_text().strip()
        comments_text = "\n".join(comments_list)
        
        full_text = f"\n{'='*40}\n[PTT] æ¨™é¡Œ: {title}\nä½œè€…: {author}\næ™‚é–“: {date}\näº’å‹•: æ¨{p_cnt}/å™“{b_cnt}\n\n[å…§æ–‡]:\n{content}\n\n[æ¨æ–‡ç´€éŒ„ ({len(comments_list)}å‰‡)]:\n{comments_text}\n"
        
        return full_text, title, date
    except: return None

# ==========================================
# 3. AI åˆ†ææ¨¡çµ„
# ==========================================
def find_valid_model(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if 'models' in data:
                valid_models = [m['name'].replace('models/', '') for m in data['models'] if 'generateContent' in m.get('supportedGenerationMethods', [])]
                if "gemini-1.5-pro" in valid_models: return "gemini-1.5-pro"
                if "gemini-1.0-pro" in valid_models: return "gemini-1.0-pro"
                if "gemini-1.5-flash" in valid_models: return "gemini-1.5-flash"
                if valid_models: return valid_models[0]
        return "gemini-1.5-flash" 
    except: return "gemini-1.5-flash"

def call_gemini_api(api_key, prompt):
    model_name = find_valid_model(api_key)
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    response = requests.post(url, headers=headers, json=data, timeout=120)
    if response.status_code == 200:
        return response.json()['candidates'][0]['content']['parts'][0]['text'], model_name
    else:
        raise Exception(f"API Error {response.status_code}")

# ==========================================
# 4. Streamlit UI
# ==========================================

with st.sidebar:
    st.header("âš™ï¸ ç³»çµ±è¨­å®š")
    saved_key = load_key()
    api_key_input = st.text_input("Gemini API Key", value=saved_key, type="password")
    if api_key_input and api_key_input != saved_key:
        save_key(api_key_input)
        st.toast("Key å·²å„²å­˜", icon="âœ…")
    st.session_state.api_key = api_key_input

    keyword_input = st.text_input("è‚¡ç¥¨ä»£è™Ÿ (ä¾‹: 2330)", value="2330")
    limit_ptt = st.number_input("PTT ç¯‡æ•¸", min_value=1, max_value=50, value=15)
    
    st.divider()

st.title("ğŸ“Š PTT è‚¡å¸‚æˆ°æƒ…å®¤ (Final Version)")
st.markdown("æ•´åˆ **å®˜æ–¹æŠ€è¡“æ•¸æ“š** èˆ‡ **PTT æ•£æˆ¶æƒ…ç·’**ï¼Œå¿«é€Ÿåˆ¤æ–·å¤šç©ºã€‚")

# ç‹€æ…‹åˆå§‹åŒ–
if "scraped_data" not in st.session_state: st.session_state.scraped_data = ""
if "tech_report" not in st.session_state: st.session_state.tech_report = ""
if "logs" not in st.session_state: st.session_state.logs = []

# --- æœå°‹æŒ‰éˆ• (åªè² è²¬æ›´æ–°è³‡æ–™ï¼Œä¸è² è²¬é¡¯ç¤º) ---
if st.button("ğŸš€ å•Ÿå‹•æˆ°æƒ…åˆ†æ", use_container_width=True):
    # æ¸…ç©ºèˆŠè³‡æ–™
    st.session_state.scraped_data = ""
    st.session_state.tech_report = ""
    st.session_state.logs = []
    
    stock_code = re.sub(r"\D", "", keyword_input)
    if not stock_code:
        st.error("è«‹è¼¸å…¥æ­£ç¢ºä»£è™Ÿ")
        st.stop()

    # 1. æŠ“æŠ€è¡“æŒ‡æ¨™
    with st.spinner("è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ä¸­..."):
        tech_report = calculate_technical_indicators(stock_code)
        st.session_state.tech_report = tech_report

    # 2. æŠ“ PTT
    keywords = keyword_input.split()
    all_text_data = ""
    ptt_links = set()
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    status_text.text("æœå°‹ PTT ä¸­...")
    
    for kw in keywords:
        soup = get_ptt_soup(f"https://www.ptt.cc/bbs/Stock/search?q={kw}")
        if soup:
            divs = soup.find_all('div', class_='title')
            if divs:
                for t in divs:
                    a = t.find('a')
                    if a: ptt_links.add("https://www.ptt.cc" + a['href'])
        time.sleep(0.2)
    
    sorted_links = sorted(list(ptt_links), key=extract_ptt_timestamp, reverse=True)[:limit_ptt]
    
    if not sorted_links:
        st.warning("âŒ æ‰¾ä¸åˆ°ç›¸é—œæ–‡ç« ")
    else:
        for i, link in enumerate(sorted_links):
            res = parse_ptt_article(link)
            if res:
                text, title, date = res
                all_text_data += text
                # å­˜å…¥ logs ä»¥ä¾¿ç¨å¾Œé¡¯ç¤º
                st.session_state.logs.append(f"ğŸ“„ [{date}] {title}")
            
            progress = (i + 1) / len(sorted_links)
            progress_bar.progress(progress)
            status_text.text(f"ä¸‹è¼‰ä¸­... {int(progress*100)}%")
            time.sleep(0.1)
        
        st.session_state.scraped_data = all_text_data
        status_text.success(f"ğŸ‰ æœå°‹å®Œæˆï¼")
        time.sleep(1) # è®“ä½¿ç”¨è€…çœ‹åˆ°å®Œæˆè¨Šæ¯
        status_text.empty() # æ¸…é™¤ç‹€æ…‹æ–‡å­—

# --- é¡¯ç¤ºå€åŸŸ (ç¨ç«‹æ–¼æŒ‰éˆ•ä¹‹å¤–ï¼Œç¢ºä¿ä¸æœƒæ¶ˆå¤±) ---
if st.session_state.tech_report or st.session_state.scraped_data:
    col1, col2 = st.columns([1, 1]) 
    
    # å·¦æ¬„ï¼šæŠ€è¡“åˆ†æ
    with col1:
        st.subheader("1. å®˜æ–¹æŠ€è¡“è¨ºæ–·")
        st.info(st.session_state.tech_report)

    # å³æ¬„ï¼šPTT åˆ—è¡¨
    with col2:
        st.subheader(f"2. PTT è¼¿æƒ…åˆ—è¡¨")
        if st.session_state.logs:
            with st.container(height=400): # å›ºå®šé«˜åº¦å·è»¸ï¼Œé¿å…é é¢å¤ªé•·
                for log in st.session_state.logs:
                    st.text(log)
        else:
            st.warning("ç„¡ç›¸é—œ PTT æ–‡ç« ")

    st.divider()
    
    # åº•éƒ¨æŒ‰éˆ•å€
    btn_col1, btn_col2 = st.columns(2)
    
    with btn_col1:
        if st.button("ğŸ§  AI æˆ°æƒ…å®˜æ·±åº¦è§£è®€", type="primary", use_container_width=True):
            if not st.session_state.api_key:
                st.warning("è«‹å…ˆè¼¸å…¥ API Key")
            else:
                with st.spinner("ğŸ¤– AI æ­£åœ¨æ¯”å°ã€ŒæŠ€è¡“è¨Šè™Ÿã€èˆ‡ã€Œæ•£æˆ¶æƒ…ç·’ (å«æ¨æ–‡)ã€..."):
                    try:
                        prompt = f"""
                        è§’è‰²ï¼šè³‡æ·±æ“ç›¤æ‰‹ã€‚
                        ä»»å‹™ï¼šåˆ†æ {keyword_input} èµ°å‹¢ã€‚
                        
                        ã€è³‡æ–™ä¾†æºã€‘
                        1. [å®˜æ–¹æŠ€è¡“é¢]:
                        {st.session_state.tech_report}
                        
                        2. [PTT è¼¿æƒ… (å«æ¨æ–‡çˆ­è«–)]:
                        {st.session_state.scraped_data[:100000]}
                        
                        è«‹è¼¸å‡ºåˆ†æå ±å‘Šï¼š
                        1. ã€å¤šç©ºæº«åº¦è¨ˆã€‘(0-100åˆ†)
                        2. ã€æŠ€è¡“é¢è¨ºæ–·ã€‘ï¼š(å¼•ç”¨ MA, RSI, KD, é‡èƒ½ï¼Œåˆ¤æ–·ç›®å‰æ˜¯å¤šé ­ã€ç©ºé ­é‚„æ˜¯ç›¤æ•´)ã€‚
                        3. ã€æ•£æˆ¶å…±è­˜ã€‘ï¼š(è«‹å¼•ç”¨ PTT æ¨æ–‡å…§å®¹ï¼Œé„‰æ°‘ç›®å‰çœ‹å¤šé‚„æ˜¯çœ‹ç©ºï¼Ÿæœ‰ç„¡åä¸²ï¼Ÿ)ã€‚
                        4. ã€è¨Šè™Ÿ vs è¼¿æƒ…ã€‘ï¼šçœŸå¯¦æŠ€è¡“æŒ‡æ¨™æœ‰æ”¯æ’é„‰æ°‘çš„çœ‹æ³•å—ï¼Ÿ
                        5. ã€æ“ä½œå»ºè­°ã€‘ï¼šåŸºæ–¼æŠ€è¡“é¢äº‹å¯¦çµ¦å‡ºå»ºè­°ã€‚
                        """
                        result, model = call_gemini_api(st.session_state.api_key, prompt)
                        st.subheader("ğŸ“Š æˆ°æƒ…åˆ†æå ±å‘Š")
                        st.markdown(result)
                    except Exception as e:
                        st.error(str(e))
                        
    with btn_col2:
        timestamp = get_tw_time_str()
        safe_kw = re.sub(r'[\\/*?:"<>|]', "_", keyword_input.replace(" ", "_"))
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´è³‡æ–™ (.txt)",
            data=f"{st.session_state.tech_report}\n\n{'='*20}\n\n{st.session_state.scraped_data}".encode("utf-8-sig"),
            file_name=f"report_{safe_kw}_{timestamp}.txt",
            mime="text/plain",
            use_container_width=True
        )