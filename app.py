import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import re
import os
from datetime import datetime

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="PTT è‚¡å¸‚åæŒ‡æ¨™è§€æ¸¬ç«™",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- æª”æ¡ˆè™•ç† (è‡ªå‹•è¨˜æ†¶åŠŸèƒ½) ---
KEY_FILE = "api_key.txt"

def load_key():
    """å¾æª”æ¡ˆè®€å– Key"""
    if os.path.exists(KEY_FILE):
        try:
            with open(KEY_FILE, "r", encoding="utf-8") as f:
                return f.read().strip()
        except: return ""
    return ""

def save_key(key):
    """å°‡ Key å¯«å…¥æª”æ¡ˆ"""
    try:
        with open(KEY_FILE, "w", encoding="utf-8") as f:
            f.write(key)
    except: pass

# --- æ ¸å¿ƒå‡½æ•¸ ---
def get_soup(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.ptt.cc/bbs/Stock/index.html',
            'Connection': 'keep-alive'
        }
        cookies = {'over18': '1'}
        response = requests.get(url, cookies=cookies, headers=headers, timeout=10)
        if response.status_code != 200: return None
        return BeautifulSoup(response.text, 'html.parser')
    except: return None

def extract_timestamp(url):
    match = re.search(r'M\.(\d+)', url)
    return int(match.group(1)) if match else 0

def parse_article(url):
    soup = get_soup(url)
    if not soup: return None
    try:
        meta = soup.find_all('span', class_='article-meta-value')
        if not meta or len(meta) < 4: return None
        
        author = meta[0].text.strip()
        title = meta[2].text.strip()
        date = meta[3].text.strip()
        main_content = soup.find(id="main-content")
        
        # --- æŠ“å–æ¨æ–‡ (å«æ™‚é–“ï¼ŒæŠ“å–å…¨éƒ¨) ---
        pushes = main_content.find_all('div', class_='push')
        
        p_cnt = sum(1 for p in pushes if 'æ¨' in p.text)
        b_cnt = sum(1 for p in pushes if 'å™“' in p.text)
        
        comments_list = []
        for p in pushes:
            try:
                tag = p.find('span', class_='push-tag').text.strip()
                user = p.find('span', class_='push-userid').text.strip()
                content = p.find('span', class_='push-content').text.strip().replace(': ', '')
                
                # æŠ“å– IP/æ™‚é–“
                ip_time_span = p.find('span', class_='push-ipdatetime')
                ip_time = ip_time_span.text.strip() if ip_time_span else ""
                
                comments_list.append(f"[{ip_time}] {tag} {user}: {content}")
            except: continue

        # æ¸…ç†ä¸»æ–‡ HTML
        for t in main_content.find_all(['div', 'span'], class_=['article-meta-tag', 'article-meta-value', 'push', 'richcontent']): 
            t.decompose()
        
        body_content = main_content.get_text().strip()
        
        # çµ„åˆå…¨æ–‡ï¼šæ¨™é¡Œ + å…§æ–‡ + æ‰€æœ‰æ¨æ–‡ (ç„¡é™åˆ¶)
        comments_text = "\n".join(comments_list)
        
        formatted_text = f"\n{'='*30}\nğŸ“„ æ¨™é¡Œ: {title}\nğŸ“… æ™‚é–“: {date}\nğŸ‘¤ ä½œè€…: {author}\nğŸ“Š äº’å‹•: æ¨ {p_cnt} | å™“ {b_cnt}\n\n[å…§æ–‡]:\n{body_content}\n\n[å®Œæ•´æ¨æ–‡ ({len(comments_list)}å‰‡)]:\n{comments_text}\n"
        return formatted_text, title, date
    except: return None

# --- AI å‘¼å«å‡½æ•¸ (è‡ªå‹•å‚™æ´ + é•·æ™‚é–“ç­‰å¾…) ---
def find_valid_model(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if 'models' in data:
                valid_models = [m['name'].replace('models/', '') for m in data['models'] if 'generateContent' in m.get('supportedGenerationMethods', [])]
                
                # å„ªå…ˆä½¿ç”¨ Proï¼Œè‹¥ç„¡å‰‡ç”¨ Flash
                if "gemini-1.5-pro" in valid_models: return "gemini-1.5-pro"
                if "gemini-1.0-pro" in valid_models: return "gemini-1.0-pro"
                if "gemini-1.5-flash" in valid_models: return "gemini-1.5-flash"
                
                if valid_models: return valid_models[0]
        return "gemini-1.5-flash" 
    except: return "gemini-1.5-flash"

def call_gemini_api(api_key, prompt):
    model_name = find_valid_model(api_key)
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    
    # è¨­å®šè¶…é•· timeout (300ç§’)ï¼Œå› ç‚º 50 ç¯‡æ–‡ç«  + å…¨æ¨æ–‡ è³‡æ–™é‡å¾ˆå¤§
    timeout = 300
    
    response = requests.post(url, headers=headers, json=data, timeout=timeout)
    if response.status_code == 200:
        return response.json()['candidates'][0]['content']['parts'][0]['text'], model_name
    else:
        # å¦‚æœ Pro çˆ†äº† (429)ï¼Œè‡ªå‹•é™ç´šå˜—è©¦ Flash
        if response.status_code == 429 and "flash" not in model_name:
            fallback_model = "gemini-1.5-flash"
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{fallback_model}:generateContent?key={api_key}"
            response = requests.post(url, headers=headers, json=data, timeout=timeout)
            if response.status_code == 200:
                return response.json()['candidates'][0]['content']['parts'][0]['text'], fallback_model
        
        raise Exception(f"API Error {response.status_code}: {response.text}")

# --- ç¶²é ä»‹é¢é‚è¼¯ ---

with st.sidebar:
    st.header("âš™ï¸ åƒæ•¸è¨­å®š")
    saved_key = load_key()
    api_key_input = st.text_input("Gemini API Key", value=saved_key, type="password")
    if api_key_input and api_key_input != saved_key:
        save_key(api_key_input)
        st.toast("ğŸ’¾ API Key å·²å„²å­˜", icon="âœ…")
    st.session_state.api_key = api_key_input

    keyword_input = st.text_input("è‚¡ç¥¨ä»£è™Ÿ (ç©ºç™½éš”é–‹)", value="2330 å°ç©é›»")
    
    # --- æ‚¨çš„è¦æ±‚ï¼šä¸Šé™ 50ï¼Œé è¨­ 10 ---
    limit_count = st.number_input("ä¸‹è¼‰ç¯‡æ•¸", min_value=1, max_value=50, value=10)
    
    st.divider()
    if saved_key:
        st.caption("âœ… ç›®å‰å·²è¼‰å…¥è‡ªå‹•å„²å­˜çš„ Key")

st.title("ğŸ›¡ï¸ PTT è‚¡å¸‚åæŒ‡æ¨™è§€æ¸¬ç«™ (V20 çµ‚æ¥µç‰ˆ)")
st.markdown("å·²å•Ÿç”¨ **å…¨æ¨æ–‡æŠ“å–** èˆ‡ **50ç¯‡å¤§é‡åˆ†æ** æ¨¡å¼ã€‚")

if "scraped_data" not in st.session_state: st.session_state.scraped_data = ""
if "logs" not in st.session_state: st.session_state.logs = []

if st.button("ğŸš€ é–‹å§‹æœå°‹ & ä¸‹è¼‰", use_container_width=True):
    st.session_state.logs = [] 
    st.session_state.scraped_data = ""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    keywords = keyword_input.split()
    links = set()
    
    for kw in keywords:
        status_text.text(f"æ­£åœ¨æœå°‹: {kw}...")
        soup = get_soup(f"https://www.ptt.cc/bbs/Stock/search?q={kw}")
        if soup:
            for t in soup.find_all('div', class_='title'):
                a = t.find('a')
                if a: links.add("https://www.ptt.cc" + a['href'])
    
    if not links:
        st.error("âŒ æ‰¾ä¸åˆ°ç›¸é—œæ–‡ç« ")
    else:
        sorted_links = sorted(list(links), key=extract_timestamp, reverse=True)[:limit_count]
        status_text.text(f"æ‰¾åˆ° {len(sorted_links)} ç¯‡ï¼Œé–‹å§‹ä¸‹è¼‰å…§å®¹...")
        
        full_text = ""
        for i, link in enumerate(sorted_links):
            res = parse_article(link)
            if res:
                text, title, date = res
                full_text += text
                st.session_state.logs.append(f"âœ… [{date}] {title}")
            else:
                st.session_state.logs.append(f"âŒ è®€å–å¤±æ•—: {link}")
            progress_bar.progress((i + 1) / len(sorted_links))
            time.sleep(0.2)
            
        st.session_state.scraped_data = full_text
        st.success(f"ğŸ‰ ä¸‹è¼‰å®Œæˆï¼å·²æŠ“å– {len(full_text)} å­—å…ƒ (å«æ‰€æœ‰æ¨æ–‡)ã€‚")

if st.session_state.logs:
    with st.expander("ğŸ“‹ æŸ¥çœ‹å·²æŠ“å–çš„æ–‡ç« åˆ—è¡¨", expanded=True):
        for log in st.session_state.logs: st.text(log)

if st.session_state.scraped_data:
    st.divider()
    st.subheader("ğŸ› ï¸ ä¸‹ä¸€æ­¥æ“ä½œ")
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if st.button("ğŸ¤– å‘¼å« Gemini é€²è¡Œåˆ†æ", type="primary", use_container_width=True):
            if not st.session_state.api_key:
                st.warning("è«‹å…ˆè¼¸å…¥ API Key")
            else:
                with st.spinner("ğŸ§  è³‡æ–™é‡è¼ƒå¤§ï¼ŒAI æ­£åœ¨é–±è®€ä¸¦åˆ†æ (å¯èƒ½éœ€æ™‚ 1-3 åˆ†é˜)..."):
                    try:
                        # å°‡ token é™åˆ¶æ”¾å¯¬åˆ° 20 è¬å­—ï¼Œç¢ºä¿èƒ½åƒä¸‹ 50 ç¯‡çš„å…¨æ¨æ–‡
                        prompt = f"""
                        è§’è‰²è¨­å®šï¼šä½ æ˜¯ä¸€ä½ç²¾é€šå°è‚¡æ•£æˆ¶å¿ƒç†å­¸èˆ‡è¡Œç‚ºé‡‘èå­¸çš„è³‡æ·±äº¤æ˜“å“¡ã€‚
                        ä»»å‹™ï¼šåˆ†æä»¥ä¸‹ PTT è‚¡æ¿è¨è«–å…§å®¹ (é€™æ˜¯å®Œæ•´çš„æ¨æ–‡ä¸²ï¼Œè«‹ç‰¹åˆ¥æ³¨æ„æƒ…ç·’çš„é€£çºŒè®ŠåŒ–èˆ‡å¤šç©ºè«–æˆ°)ã€‚
                        
                        è«‹è¼¸å‡ºç°¡æ½”å ±å‘Šï¼š
                        1. ã€æƒ…ç·’æº«åº¦è¨ˆã€‘ (0-100åˆ†)ï¼š0=æ¥µåº¦ææ…Œ(è²·é»)ï¼Œ100=æ¥µåº¦ç‹‚ç†±(è³£é»)ã€‚
                        2. ã€æ•£æˆ¶å…±è­˜ã€‘ï¼šå¤§å®¶ç¾åœ¨ä¸»è¦åœ¨çœ‹å¤šé‚„æ˜¯çœ‹ç©ºï¼Ÿæœ‰ç„¡åä¸²ï¼Ÿ
                        3. ã€åæŒ‡æ¨™æ“ä½œå»ºè­°ã€‘ï¼šåŸºæ–¼ã€Œäººå¤šçš„åœ°æ–¹ä¸è¦å»ã€åŸå‰‡ï¼Œç¾åœ¨é©åˆé€²å ´ã€å‡ºå ´é‚„æ˜¯è§€æœ›ï¼Ÿ
                        4. ã€é—œéµè­‰æ“šã€‘ï¼šå¼•ç”¨ 1-2 å‰‡æœ€å…·ä»£è¡¨æ€§çš„æ¨æ–‡ (è«‹åŒ…å«æ™‚é–“é»)ã€‚

                        è³‡æ–™å…§å®¹ï¼š
                        {st.session_state.scraped_data[:200000]}
                        """
                        result, model_used = call_gemini_api(st.session_state.api_key, prompt)
                        
                        st.divider()
                        st.subheader(f"ğŸ“Š åˆ†æå ±å‘Š (ä½¿ç”¨æ¨¡å‹: {model_used})")
                        st.markdown(result)
                    except Exception as e:
                        st.error(f"åˆ†æå¤±æ•—: {str(e)}")

    with col2:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_kw = re.sub(r'[\\/*?:"<>|]', "_", keyword_input.replace(" ", "_"))
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´æ–‡å­—æª” (.txt)",
            data=st.session_state.scraped_data,
            file_name=f"ptt_{safe_kw}_{timestamp}.txt",
            mime="text/plain",
            use_container_width=True
        )

st.divider()
st.caption("Powered by Streamlit & Google Gemini API")